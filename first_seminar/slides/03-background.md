## Dimension Reduction:

Typically, many dimensions are extraneous/redundant. 

- **Computational issues**: Curse of dimensionality, memory constraints, processing time
- **Visualization**: Human perception limited to 2D/3D representations
- **Noise reduction**: Remove irrelevant features that obscure patterns


## Curse of Dimensionality
In high dimensions, geometric intuition breaks down 

$\frac{V_\text{hypersphere}}{V_\text{hypercube}} = \frac{\pi^{d/2}}{d2^{d-1}\Gamma(d/2)} \to 0 \text{ as } d \to \infty $
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 500 300" style="max-width: 70%; height: auto;" >
  <defs>
    <radialGradient gradientUnits="userSpaceOnUse" cx="269.467" cy="330.533" r="69.467" id="gradient-0" gradientTransform="matrix(0.866555, 0, 0, 0.866555, 114.522033, -130.979114)">
      <stop offset="0" style="stop-color: rgb(50.588% 100% 93.333%)"></stop>
      <stop offset="1" style="stop-color: rgb(0% 59.236% 53.779%)"></stop>
    </radialGradient>
  </defs>
  <rect x="81.459" y="87.833" width="135.342" height="135.342" style="stroke: rgb(0, 0, 0); fill: rgb(255, 0, 0);"></rect>
  <ellipse style="stroke: rgb(0, 0, 0); fill: rgba(72, 240, 255, 0.8);" cx="149.13" cy="155.504" rx="67.671" ry="67.671"></ellipse>
  <path style="stroke: rgb(0, 0, 0); fill: rgba(255, 0, 0, 0.61);" d="M 273.233 127.476 L 372.19 127.231"></path>
  <ellipse style="stroke: rgb(0, 0, 0); fill: url(#gradient-0);" cx="348.03" cy="155.446" rx="60.197" ry="60.197"></ellipse>
  <text style="fill: rgb(255, 255, 255); font-family: &quot;Arial&quot;, sans-serif; font-size: 28px; white-space: pre;" x="308.806" y="162.934">52.4%</text>
  <rect x="272.19" y="127.231" width="100" height="100" style="stroke: rgb(0, 0, 0); fill: rgba(255, 0, 0, 0.61);"></rect>
  <path style="stroke: rgb(0, 0, 0); fill: rgba(255, 0, 0, 0.61);" d="M 273.233 126.317 L 323.638 80.546 L 422.711 80.546 L 372.19 127.231 L 273.233 126.317 Z"></path>
  <path style="stroke: rgb(0, 0, 0); fill: rgba(255, 0, 0, 0.61);" d="M 423.291 80.546 L 423.87 180.778 L 372.19 227.231 L 372.19 127.231 L 423.291 80.546 Z"></path>
  <text style="white-space: pre; fill: rgb(51, 51, 51); font-family: &quot;Arial&quot;, sans-serif; font-size: 28px;" x="110.08" y="163.512">78.5%</text>
</svg>


## Two Approaches:
- **Matrix Factorization**: Create a basis of archetypes
- **Graph Embeddings**: Use local topology


## Matrix Factorization Techniques:

- Principal Component Analysis (PCA)

- Linear Auto-Encoder

- Non-negative Matrix Factorization (NMF)

- GloVe (Global Vectors)

- Latent Dirichlet Allocation (LDA)



## Matrix Factorization Idea:

- **Decompose** data matrix $X$
$$ X \approx UV $$

- $U =$ Representation of $X$ in lower dimension

- $V =$ Archetypes

So we want $X \approx$ a linear combination of archetypes


## General Form

- **X**: Original data $(N \times D)$
- **U**: Data in reduced space $(N \times k)$ 
- **V**: Transformation matrix $(D \times k)$
- **k**: Target dimensionality $(k << D)$


## Matrix Factorization Optimization:

**Objective**: Find matrices U and V that minimize reconstruction error
$$ \sum_{i=1}^{N} \sum_{j=1}^{D} \mathbf{\text{Loss}}\left\(X_{ij}, (UV)_{ij} \right\) $$

With potentially some restraints.


## PCA

Minimizes mean squared error:

$$ \sum_{i=1}^{N} \sum_{j=1}^{D} \left\(X_{ij} - (UV)_{ij} \right\)^2 $$


## Sparse PCA 

$$ \sum_{i=1}^{N} \sum_{j=1}^{D} \left\(X_{ij} - (UV)_{ij} \right\)^2 $$

With the constraints:
$$||U||_2 = 1$$
$$||U||_0 \leq k$$


## More information:
If you suspect your data is generated by some model $\Theta$:
$$ X \sim \mathbf{\text{Pr}}(\cdot | \Theta)$$

Then we can instead try to reconstruct $\Theta = UV$.

- Let the loss be the negative log likelihood of observing $X$ given $\Theta$.

$$ -log(P(X_i | \Theta_i))$$


## Normal Model = PCA:
If $\Theta$ is a normal distribution then:

$$-log(P(X_i | \Theta_i)) = \sum_{i=1}^{N} \sum_{j=1}^{D} \frac{1}{2}((UV)\_{ij})^2 - X_{ij} \cdot(UV)\_{ij} $$

$$ \hspace{5cm} ^* = \sum_{i=1}^{N} \sum_{j=1}^{D} \frac{1}{2} \left\(X_{ij} - (UV)_{ij} \right\)^2 $$


## Strengths
- Fast matrix operations
- Easy to embed new points

## Limitations
- May miss local structure
- May blend unrelated/non-linear features


## Neighbor Graph Embeddings:

### General Approach
1. **Graph construction**: Connect each point to k nearest neighbors
2. **Weight assignment**: Assign edge weights based on similarity/distance
3. **Embedding optimization**: Embedd as a force directed graph using the weights


## Strengths
- Handles non-linear structure / relationships
- Preserves local structure

## Limitations
- Often $O(n^2)$ or higher complexity
- Difficult to embed new points


## Neighbor Graph Dimension Reduction Methods:

- t-SNE

- Isomap

- Locally Linear Embedding (LLE)

- **UMAP** (Uniform Manifold Approximation and Projection)
